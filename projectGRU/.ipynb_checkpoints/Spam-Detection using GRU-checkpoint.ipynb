{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAM DETECTION USING GRU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/saitej/snap/jupyter/common/lib/python3.7/site-packages (3.2.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/saitej/snap/jupyter/common/lib/python3.7/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/saitej/snap/jupyter/common/lib/python3.7/site-packages (from matplotlib) (1.17.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/saitej/snap/jupyter/common/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/saitej/snap/jupyter/common/lib/python3.7/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /snap/jupyter/6/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: six in /snap/jupyter/6/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN,GRU, Embedding, Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Mail Category\n",
      "5724   4 color printing special  request additional ...     spam\n",
      "5725  naturally irresistible your corporate identity...     spam\n",
      "5726  you got this mail that you have received a sch...      ham\n",
      "5727  the stock trading gunslinger  fanny is merrill...     spam\n",
      "5728  unbelievable new homes made easy  im wanting t...     spam\n",
      "  Category                                               Mail\n",
      "0     spam  You got this mail because you have won 1lakh d...\n",
      "1      ham  Go until jurong point, crazy.. Available only ...\n",
      "2      ham                      Ok lar... Joking wif u oni...\n",
      "3     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "4      ham  U dun say so early hor... U c already then say...\n",
      "     Category                                               Mail\n",
      "5569     spam  This is the 2nd time we have tried 2 contact u...\n",
      "5570      ham               Will Ã¼ b going to esplanade fr home?\n",
      "5571      ham  Pity, * was in mood for that. So...any other s...\n",
      "5572      ham  The guy did some bitching but I acted like i'd...\n",
      "5573      ham                         Rofl. Its true to its name\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./spams.csv\")\n",
    "data1 = pd.read_csv(\"./spam_text_mails_data.csv\")\n",
    "print(data.tail())\n",
    "print(data1.head())\n",
    "print(data1.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mails:  11303\n",
      "Number of labels:  11303\n"
     ]
    }
   ],
   "source": [
    "#SEPARATING MAILS AND LABELS(HAM OR SPAM)\n",
    "mails = []\n",
    "labels = []\n",
    "for index, row in data.iterrows():\n",
    "    mails.append(row['Mail'])\n",
    "    if row['Category'] == 'ham':\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "for index, row in data1.iterrows():\n",
    "    mails.append(row['Mail'])\n",
    "    if row['Category'] == 'ham':\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "mails = np.asarray(mails)\n",
    "labels = np.asarray(labels)\n",
    "   \n",
    "\n",
    "print(\"Number of mails: \", len(mails))\n",
    "print(\"Number of labels: \", len(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOKENIZATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 10000\n",
    "max_len = 500\n",
    "\n",
    "# Ignore all words except the 10000 most common words\n",
    "tokenizer = Tokenizer(num_words=max_vocab)\n",
    "# Calculate the frequency of words\n",
    "tokenizer.fit_on_texts(mails)\n",
    "# Convert array of mails to list of sequences of integers\n",
    "sequences = tokenizer.texts_to_sequences(mails)\n",
    "\n",
    "# Dict keeping track of words to integer index\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PADDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (11303, 500)\n"
     ]
    }
   ],
   "source": [
    "# Convert the array of sequences(of integers) to 2D array with padding\n",
    "# maxlen specifies the maximum length of sequence (truncated if longer, padded if shorter)\n",
    "data = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "print(\"data shape: \", data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEPARATING THE DATA FOR TRAINING AND TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use 80% of data for training & validation(80% train, 20% validation) and 20% for testing\n",
    "train_samples = int(len(mails)*0.8)\n",
    "\n",
    "mails_train = data[:train_samples]\n",
    "labels_train = labels[:train_samples]\n",
    "\n",
    "mails_test = data[train_samples:len(mails)-2]\n",
    "labels_test = labels[train_samples:len(mails)-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING GRU MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 32)           320000    \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 32)                6240      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 326,273\n",
      "Trainable params: 326,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_mat_columns=32\n",
    "# Construct the SimpleRNN model\n",
    "model = Sequential()\n",
    "    ## Add embedding layer to convert integer encoding to word embeddings(the model learns the\n",
    "    ## embedding matrix during training), embedding matrix has max_vocab as no. of rows and chosen\n",
    "    ## no. of columns\n",
    "model.add(Embedding(input_dim=max_vocab, output_dim=embedding_mat_columns, input_length=max_len))\n",
    "\n",
    "\n",
    "model.add(GRU(units=embedding_mat_columns))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING AND TESTING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6238 samples, validate on 2804 samples\n",
      "Epoch 1/5\n",
      "6238/6238 [==============================] - 28s 4ms/step - loss: 0.0642 - acc: 0.9824 - val_loss: 0.3681 - val_acc: 0.8816\n",
      "Epoch 2/5\n",
      "6238/6238 [==============================] - 28s 4ms/step - loss: 0.0316 - acc: 0.9907 - val_loss: 0.2596 - val_acc: 0.9112\n",
      "Epoch 3/5\n",
      "6238/6238 [==============================] - 28s 4ms/step - loss: 0.0209 - acc: 0.9942 - val_loss: 0.2183 - val_acc: 0.9315\n",
      "Epoch 4/5\n",
      "6238/6238 [==============================] - 28s 5ms/step - loss: 0.0155 - acc: 0.9957 - val_loss: 0.2871 - val_acc: 0.8973\n",
      "Epoch 5/5\n",
      "6238/6238 [==============================] - 28s 5ms/step - loss: 0.0122 - acc: 0.9966 - val_loss: 0.2163 - val_acc: 0.9312\n",
      "2259/2259 [==============================] - 4s 2ms/step\n",
      "Test loss is 0.23 accuracy is 0.93  \n"
     ]
    }
   ],
   "source": [
    " #plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    # Training the model\n",
    "model.fit(mails_train, labels_train, epochs=5, batch_size=60, validation_split=0.31)\n",
    "\n",
    "    # Testing the model\n",
    "pred = model.predict_classes(mails_test)\n",
    "acc = model.evaluate(mails_test, labels_test)\n",
    "print(\"Test loss is {0:.2f} accuracy is {1:.2f}  \".format(acc[0],acc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING WITH CUSTOM MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "# Constructing a custom mail to check model\n",
    "custom_mail = 'Congratulations you have won a prize of million dollars and world tour'\n",
    "\n",
    "custom_mail = custom_mail.lower().split(' ')\n",
    "test_seq = np.array([word_index[word] for word in custom_mail])\n",
    "\n",
    "test_seq = np.pad(test_seq, (500-len(test_seq), 0), 'constant', constant_values=(0))\n",
    "test_seq = test_seq.reshape(1, 500)\n",
    "        \n",
    "\n",
    "pred = model.predict_classes(test_seq)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "# Constructing a custom mail to check model\n",
    "custom_mai = 'Congratulations brother for your results in education'\n",
    "custom_mai = custom_mai.lower().split(' ')\n",
    "test_seq = np.array([word_index[word] for word in custom_mai])\n",
    "\n",
    "test_seq = np.pad(test_seq, (500-len(test_seq), 0), 'constant', constant_values=(0))\n",
    "test_seq = test_seq.reshape(1, 500)\n",
    "        \n",
    "\n",
    "pred = model.predict_classes(test_seq)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
