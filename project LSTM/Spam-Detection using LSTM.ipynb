{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAM DETECTION USING LSTM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN,GRU,LSTM, Embedding, Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./spams.csv\")\n",
    "data1 = pd.read_csv(\"./spam_text_mails_data.csv\")\n",
    "print(data.tail())\n",
    "print(data1.head())\n",
    "print(data1.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEPARATING MAILS AND LABELS(HAM OR SPAM)\n",
    "mails = []\n",
    "labels = []\n",
    "for index, row in data.iterrows():\n",
    "    mails.append(row['Mail'])\n",
    "    if row['Category'] == 'ham':\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "for index, row in data1.iterrows():\n",
    "    mails.append(row['Mail'])\n",
    "    if row['Category'] == 'ham':\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "mails = np.asarray(mails)\n",
    "labels = np.asarray(labels)\n",
    "   \n",
    "\n",
    "print(\"Number of mails: \", len(mails))\n",
    "print(\"Number of labels: \", len(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOKENIZATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 10000\n",
    "max_len = 500\n",
    "\n",
    "# Ignore all words except the 10000 most common words\n",
    "tokenizer = Tokenizer(num_words=max_vocab)\n",
    "# Calculate the frequency of words\n",
    "tokenizer.fit_on_texts(mails)\n",
    "# Convert array of mails to list of sequences of integers\n",
    "sequences = tokenizer.texts_to_sequences(mails)\n",
    "\n",
    "# Dict keeping track of words to integer index\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PADDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the array of sequences(of integers) to 2D array with padding\n",
    "# maxlen specifies the maximum length of sequence (truncated if longer, padded if shorter)\n",
    "data = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "print(\"data shape: \", data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEPARATING THE DATA FOR TRAINING AND TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use 80% of data for training & validation(80% train, 20% validation) and 20% for testing\n",
    "train_samples = int(len(mails)*0.8)\n",
    "\n",
    "mails_train = data[:train_samples]\n",
    "labels_train = labels[:train_samples]\n",
    "\n",
    "mails_test = data[train_samples:len(mails)-2]\n",
    "labels_test = labels[train_samples:len(mails)-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_mat_columns=32\n",
    "# Construct the SimpleRNN model\n",
    "model = Sequential()\n",
    "    ## Add embedding layer to convert integer encoding to word embeddings(the model learns the\n",
    "    ## embedding matrix during training), embedding matrix has max_vocab as no. of rows and chosen\n",
    "    ## no. of columns\n",
    "model.add(Embedding(input_dim=max_vocab, output_dim=embedding_mat_columns, input_length=max_len))\n",
    "\n",
    "model.add(LSTM(units=embedding_mat_columns))\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING AND TESTING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    # Training the model\n",
    "model.fit(mails_train, labels_train, epochs=5, batch_size=60, validation_split=0.2)\n",
    "\n",
    "    # Testing the model\n",
    "pred = model.predict_classes(mails_test)\n",
    "acc = model.evaluate(mails_test, labels_test)\n",
    "print(\"Test loss is {0:.2f} accuracy is {1:.2f}  \".format(acc[0],acc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING WITH CUSTOM MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing a custom mail to check model\n",
    "custom_mail = 'Congratulations you got this mail because you have won a prize of million dollars and world tour'\n",
    "\n",
    "custom_mail = custom_mail.lower().split(' ')\n",
    "test_seq = np.array([word_index[word] for word in custom_mail])\n",
    "\n",
    "test_seq = np.pad(test_seq, (500-len(test_seq), 0), 'constant', constant_values=(0))\n",
    "test_seq = test_seq.reshape(1, 500)\n",
    "        \n",
    "\n",
    "pred = model.predict_classes(test_seq)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing a custom mail to check model\n",
    "custom_mai = 'Congratulations brother for your results in education'\n",
    "custom_mai = custom_mai.lower().split(' ')\n",
    "test_seq = np.array([word_index[word] for word in custom_mai])\n",
    "\n",
    "test_seq = np.pad(test_seq, (500-len(test_seq), 0), 'constant', constant_values=(0))\n",
    "test_seq = test_seq.reshape(1, 500)\n",
    "        \n",
    "\n",
    "pred = model.predict_classes(test_seq)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
